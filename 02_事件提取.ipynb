{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5146ae8",
   "metadata": {},
   "source": [
    "# 筆記本 2：使用大語言模型進行對話處理\n",
    "\n",
    "在這個教學範例中，我們會學習如何根據不同的 API 供應商（Google 或 OpenAI）使用大語言模型來處理對話記錄。\n",
    "\n",
    "### 目標\n",
    "- 讀取歷史對話記錄。\n",
    "- 使用大語言模型進行互動，如 Google 的 Gemini 或 OpenAI 的 GPT-4。\n",
    "- 儲存模型生成的回應。\n",
    "\n",
    "此範例將幫助你透過 API 的方式與大語言模型進行互動，並自訂系統設定檔讓模型產生滿足你的需求的答案。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ede053",
   "metadata": {},
   "source": [
    "### 必要套件\n",
    "首先，我們需要安裝兩個必要的 API 套件：\n",
    "- `google.generativeai`: 用來與 Google 的大語言模型互動（例如 Gemini）。\n",
    "- `openai`: 用來與 OpenAI 的 GPT-4 等模型進行互動。\n",
    "\n",
    "使用以下命令來安裝這些套件：\n",
    "```bash\n",
    "!pip install google-generativeai openai\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b695a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安裝相關套件\n",
    "!pip install google-generativeai openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12296b90",
   "metadata": {},
   "source": [
    "### 步驟 1: 定義命令行參數解析模組\n",
    "我們首先定義一個自訂的解析器來處理命令行參數，這將幫助我們從命令行讀取相關的選項，如 API 金鑰、模型名稱、系統設定檔等等。這些參數將會被用來在後續的步驟中做處理。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0388d51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import json\n",
    "\n",
    "class CustomArgumentParser(argparse.ArgumentParser):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def print_help(self, file=None):\n",
    "        # 自訂顯示的幫助訊息\n",
    "        help_message = f\"\"\"使用方法: {self.prog} [-h] -K 金鑰 -L 大語言模型 -S 系統設定檔 -H 對話記錄檔案 -I 輸入檔案 -O 輸出檔案 -P API供應商{{google或openai}}\n",
    "\n",
    "使用大語言模型處理對話記錄\n",
    "\n",
    "選項:\n",
    "  -h, --help            顯示此幫助訊息並退出\n",
    "  -K KEY, --key KEY     API 金鑰\n",
    "  -L LLM, --llm LLM     大語言模型的名稱 (例如 'gemini-1.5-pro' 或 'gpt-4o')\n",
    "  -S SYSTEM, --system SYSTEM\n",
    "                        系統設定檔 (JSON 格式)\n",
    "  -H HISTORY, --history HISTORY\n",
    "                        對話記錄檔案 (JSON 格式)\n",
    "  -I INPUT, --input INPUT\n",
    "                        輸入檔案\n",
    "  -O OUTPUT, --output OUTPUT\n",
    "                        輸出檔案\n",
    "  -P {{google,openai}}, --provider {{google,openai}}\n",
    "                        選擇使用的 API 供應商 ('google' 或 'openai')\n",
    "        \"\"\"\n",
    "        print(help_message, file=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4f0d0d",
   "metadata": {},
   "source": [
    "### 步驟 2: 定義主程序\n",
    "這個主程序的功能是：從命令參數中讀取設定，根據指定的 API 供應商（Google 或 OpenAI）來進行兩種不同的處理流程，應用對應的大語言模型。\n",
    "\n",
    "#### 步驟包括\n",
    "1. **讀取系統設定檔**：這是設定如何調耳大語言模型的參數，比如溫度（temperature）等生成設置。\n",
    "2. **讀取對話記錄**：歷史聊天記錄是一個可選的參數，我們可以使用它來提供上下文給模型。\n",
    "3. **使用模型生成回應**：根據指定的 API 供應商來發送請求，並進行模型的回應生成。\n",
    "4. **保存結果**：將生成的回應寫入指定的輸出檔案中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06db2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import google.generativeai as genai\n",
    "import openai\n",
    "\n",
    "def main():\n",
    "    # 使用 CustomArgumentParser 處理命令列參數\n",
    "    parser = CustomArgumentParser(description=\"使用大語言模型處理對話記錄\")\n",
    "\n",
    "    # 添加命令列選項\n",
    "    parser.add_argument(\"-K\", \"--key\", required=True, help=\"API 金鑰\")\n",
    "    parser.add_argument(\"-L\", \"--llm\", required=True,\n",
    "                        help=\"處理的模型名稱 (例如 'gemini-1.5-pro' 或 'gpt-4o')\")\n",
    "    parser.add_argument(\"-S\", \"--system\", required=True,\n",
    "                        help=\"系統設定檔 (JSON 格式)\")\n",
    "    parser.add_argument(\"-H\", \"--history\", required=True,\n",
    "                        help=\"對話記錄檔案 (JSON 格式)\")\n",
    "    parser.add_argument(\"-I\", \"--input\", required=True, help=\"輸入檔案\")\n",
    "    parser.add_argument(\"-O\", \"--output\", required=True, help=\"輸出的檔案\")\n",
    "    parser.add_argument(\"-P\", \"--provider\", required=True,\n",
    "                        choices=['google', 'openai'], help=\"選擇使用的 API 供應商 ('google' 或 'openai')\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # 讀取系統設定檔 (JSON 格式)\n",
    "    with open(args.system, \"r\", encoding=\"utf-8\") as system_file:\n",
    "        system_config = json.load(system_file)\n",
    "        system_instruction = system_config.get(\"instruction\", \"\")\n",
    "\n",
    "    # 讀取對話歷史 (JSON 格式)\n",
    "    with open(args.history, \"r\", encoding=\"utf-8\") as history_file:\n",
    "        history = json.load(history_file)\n",
    "\n",
    "    # 讀取輸入檔案 (純文字格式)\n",
    "    with open(args.input, \"r\", encoding=\"utf-8\") as input_file:\n",
    "        message = input_file.read()\n",
    "\n",
    "    # 根據不同的 API 供應商進行對話\n",
    "    if args.provider == 'google':\n",
    "        # 使用 Google API 的處理方式\n",
    "        genai.configure(api_key=args.key)\n",
    "\n",
    "        # 設定模型配置\n",
    "        generation_config = {\n",
    "            \"temperature\": system_config.get(\"temperature\", 1),\n",
    "            \"top_p\": system_config.get(\"top_p\", 0.95),\n",
    "            \"top_k\": system_config.get(\"top_k\", 64),\n",
    "            \"max_output_tokens\": system_config.get(\"max_output_tokens\", 8192),\n",
    "            \"response_mime_type\": system_config.get(\"response_mime_type\", \"text/plain\")\n",
    "        }\n",
    "\n",
    "        model = genai.GenerativeModel(\n",
    "            model_name=args.llm,\n",
    "            generation_config=generation_config,\n",
    "            system_instruction=system_instruction,\n",
    "        )\n",
    "\n",
    "        # 開始對話\n",
    "        chat_session = model.start_chat(history=history)\n",
    "\n",
    "        # 送出訊息並取得回應\n",
    "        response = chat_session.send_message({\n",
    "            \"role\": \"user\",\n",
    "            \"parts\": [message]\n",
    "        })\n",
    "\n",
    "        generated_message = response.text\n",
    "    \n",
    "    elif args.provider == 'openai':\n",
    "        # 使用 OpenAI API 的處理方式\n",
    "        client = openai.OpenAI(api_key=args.key)\n",
    "\n",
    "        msg_list = [{\"role\": \"system\", \"content\": system_instruction}\n",
    "                    ] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "        \n",
    "        # 設定模型配置\n",
    "        generation_config = {\n",
    "            \"temperature\": system_config.get(\"temperature\", 1),\n",
    "            \"top_p\": system_config.get(\"top_p\", 0.95),\n",
    "            \"top_k\": system_config.get(\"top_k\", 64),\n",
    "            \"max_output_tokens\": system_config.get(\"max_output_tokens\", 8192),\n",
    "            \"response_mime_type\": system_config.get(\"response_mime_type\", \"text/plain\"),\n",
    "            \"frequency_penalty\": system_config.get(\"frequency_penalty\", 0),\n",
    "            \"presence_penalty\": system_config.get(\"presence_penalty\", 0),\n",
    "            \"response_format\": system_config.get(\"response_format\", {\"type\": \"text\"})\n",
    "        }        \n",
    "\n",
    "        # 開始對話\n",
    "        response = client.chat.completions.create(\n",
    "            model=args.llm,\n",
    "            messages=msg_list,\n",
    "            temperature=generation_config[\"temperature\"],\n",
    "            max_tokens=generation_config[\"max_output_tokens\"],\n",
    "            top_p=generation_config[\"top_p\"],\n",
    "            frequency_penalty=generation_config[\"frequency_penalty\"],\n",
    "            presence_penalty=generation_config[\"presence_penalty\"],\n",
    "            response_format=generation_config[\"response_format\"]\n",
    "        )\n",
    "\n",
    "        generated_message = response.choices[0].message.content\n",
    "\n",
    "    # 將回應保存至輸出檔案\n",
    "    with open(args.output, \"w\", encoding=\"utf-8\") as output_file:\n",
    "        output_file.write(generated_message)\n",
    "\n",
    "    print(f\"\\n\\r回應已儲存至 {args.output}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # 模擬命令列參數\n",
    "    # for google\n",
    "    # sys.argv = ['02_extract_event_mentions.py', '-K', 'YOUR_KEY', '-L', 'gemini-1.5-pro', '-S', 'system_config_google.json', '-H', 'history_google.json', '-I', 'output_summary.txt', '-O', 'event_log.txt', '-P', 'google']\n",
    "    # for openai\n",
    "    sys.argv = ['02_extract_event_mentions.py', '-K', 'YOUR_KEY', '-L', 'gpt-4o', '-S', 'system_config_openai.json', '-H', 'history_openai.json', '-I', 'output_summary.txt', '-O', 'event_log.txt', '-P', 'openai']\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a9e322",
   "metadata": {},
   "source": [
    "### 結論\n",
    "- 在這個範例中，我們學習了如何根據不同的語言模型提供商（Google 和 OpenAI）來和大語言模型進行互動。\n",
    "- 我們的程式是高度可配置的，可以根據自己的需求調整語言模型、溫度、回應生成的最大字數、對話歷史等等。\n",
    "- 接下來，你可以使用這些工具來進行更深入的自然語言處理應用。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
